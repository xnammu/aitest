{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/xnammu/aitest/blob/main/notebooks/invokeai-latest.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **<font color=\"orange\">INVOKE 6.8.0</font>**\n",
        "### Por ArteIA ğŸ¤–ğŸ˜ºğŸ¨  \n",
        "[ğŸ‘‰ Visita el canal de YouTube](https://www.youtube.com/@arteia)\n",
        "\n",
        "Este notebook te permite usar **Invoke AI** desde Google Colab, con una interfaz grÃ¡fica completa, sin necesidad de instalaciÃ³n local ni conocimientos tÃ©cnicos.  EstÃ¡ diseÃ±ado para que cualquiera pueda generar imÃ¡genes con IA desde un navegador, sin importar las caracterÃ­sticas de su equipo."
      ],
      "metadata": {
        "id": "WWTQYvEc9A25"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "fqN8UeMw7syM",
        "cellView": "form",
        "outputId": "e20f9e8f-937d-4563-8b31-89cf562fe1e8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/root/invokeai\n",
            "Collecting virtualenv\n",
            "  Downloading virtualenv-20.35.4-py3-none-any.whl.metadata (4.6 kB)\n",
            "Collecting distlib<1,>=0.3.7 (from virtualenv)\n",
            "  Downloading distlib-0.4.0-py2.py3-none-any.whl.metadata (5.2 kB)\n",
            "Requirement already satisfied: filelock<4,>=3.12.2 in /usr/local/lib/python3.12/dist-packages (from virtualenv) (3.20.0)\n",
            "Requirement already satisfied: platformdirs<5,>=3.9.1 in /usr/local/lib/python3.12/dist-packages (from virtualenv) (4.5.1)\n",
            "Downloading virtualenv-20.35.4-py3-none-any.whl (6.0 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m6.0/6.0 MB\u001b[0m \u001b[31m122.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading distlib-0.4.0-py2.py3-none-any.whl (469 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m469.0/469.0 kB\u001b[0m \u001b[31m40.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: distlib, virtualenv\n",
            "Successfully installed distlib-0.4.0 virtualenv-20.35.4\n",
            "created virtual environment CPython3.12.12.final.0-64 in 359ms\n",
            "  creator CPython3Posix(dest=/root/invokeai/.venv, clear=False, no_vcs_ignore=False, global=False)\n",
            "  seeder FromAppData(download=False, pip=bundle, via=copy, app_data_dir=/root/.local/share/virtualenv)\n",
            "    added seed packages: pip==25.3\n",
            "  activators BashActivator,CShellActivator,FishActivator,NushellActivator,PowerShellActivator,PythonActivator\n",
            "----------------------------------------\n",
            "âœ… BLOQUE 1 completado con Ã©xito. â¡ï¸ Ejecuta el BLOQUE 2 para Instalar Invoke\n"
          ]
        }
      ],
      "source": [
        "#@markdown ## âš™ï¸ BLOQUE 1 â€“ Preparar entorno de trabajo\n",
        "#@markdown\n",
        "#@markdown > En este paso vamos a crear la carpeta donde instalaremos Invoke y configurar el entorno virtual.<br>\n",
        "#@markdown > â­ï¸ **Ejecuta este bloque y espera a que finalice antes de pasar al siguiente.**\n",
        "\n",
        "# Creamos la carpeta donde instalaremos Invoke AI\n",
        "!mkdir -p ~/invokeai\n",
        "%cd ~/invokeai\n",
        "\n",
        "# Instalamos virtualenv y creamos el entorno con Python 3\n",
        "!pip install virtualenv\n",
        "!virtualenv .venv --python=python3\n",
        "print(\"----------------------------------------\")\n",
        "print(\"âœ… BLOQUE 1 completado con Ã©xito. â¡ï¸ Ejecuta el BLOQUE 2 para Instalar Invoke\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown ## ğŸ”§ BLOQUE 2 â€“ Instalar Invoke AI y Cloudflared\n",
        "#@markdown\n",
        "#@markdown > Vamos a instalar **Invoke AI** y la herramienta **Cloudflared** para acceder a la interfaz web desde cualquier navegador.<br>\n",
        "#@markdown > Esto puede tardar unos minutos.<br>\n",
        "#@markdown > â­ï¸ Ejecuta este bloque y espera a que aparezca **â€œâœ… BLOQUE 2 completado con Ã©xito.â€**<br>\n",
        "#@markdown > Por Ãºltimo, ejecuta el siguiente bloque.\n",
        "\n",
        "\n",
        "# ğŸ”§ BLOQUE 2 â€“ Instalar Invoke AI desde PyPI\n",
        "# Instalamos Invoke AI\n",
        "!.venv/bin/pip install invokeai==6.8.0\n",
        "print(\"âœ… Invoke 6.8.0 instalado correctamente.\")\n",
        "\n",
        "# Instalamos Cloudflared\n",
        "!wget -q https://github.com/cloudflare/cloudflared/releases/latest/download/cloudflared-linux-amd64.deb\n",
        "!dpkg -i cloudflared-linux-amd64.deb\n",
        "\n",
        "print(\"âœ… Cloudflared instalado correctamente.\")\n",
        "print(\"----------------------------------------\")\n",
        "print(\"âœ… BLOQUE 2 completado con Ã©xito. â¡ï¸ Ejecuta el BLOQUE 3 para lanzar la interfaz.\")\n"
      ],
      "metadata": {
        "id": "SyGfYCzoCZCX",
        "cellView": "form",
        "outputId": "c39e9276-9e6f-4bb6-8d13-a2f0bb10af53",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting invokeai==6.8.0\n",
            "  Downloading invokeai-6.8.0-py3-none-any.whl.metadata (24 kB)\n",
            "Collecting accelerate (from invokeai==6.8.0)\n",
            "  Downloading accelerate-1.12.0-py3-none-any.whl.metadata (19 kB)\n",
            "Collecting bitsandbytes (from invokeai==6.8.0)\n",
            "  Downloading bitsandbytes-0.49.0-py3-none-manylinux_2_24_x86_64.whl.metadata (10 kB)\n",
            "Collecting compel==2.1.1 (from invokeai==6.8.0)\n",
            "  Downloading compel-2.1.1-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting diffusers==0.33.0 (from diffusers[torch]==0.33.0->invokeai==6.8.0)\n",
            "  Downloading diffusers-0.33.0-py3-none-any.whl.metadata (20 kB)\n",
            "Collecting gguf (from invokeai==6.8.0)\n",
            "  Downloading gguf-0.17.1-py3-none-any.whl.metadata (4.3 kB)\n",
            "Collecting mediapipe==0.10.14 (from invokeai==6.8.0)\n",
            "  Downloading mediapipe-0.10.14-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.7 kB)\n",
            "Collecting numpy<2.0.0 (from invokeai==6.8.0)\n",
            "  Downloading numpy-1.26.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "Collecting onnx==1.16.1 (from invokeai==6.8.0)\n",
            "  Downloading onnx-1.16.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (16 kB)\n",
            "Collecting onnxruntime==1.19.2 (from invokeai==6.8.0)\n",
            "  Downloading onnxruntime-1.19.2-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.5 kB)\n",
            "Collecting opencv-contrib-python (from invokeai==6.8.0)\n",
            "  Downloading opencv_contrib_python-4.12.0.88-cp37-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (19 kB)\n",
            "Collecting safetensors (from invokeai==6.8.0)\n",
            "  Downloading safetensors-0.7.0-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.1 kB)\n",
            "Collecting sentencepiece==0.2.0 (from invokeai==6.8.0)\n",
            "  Downloading sentencepiece-0.2.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.7 kB)\n",
            "Collecting spandrel (from invokeai==6.8.0)\n",
            "  Downloading spandrel-0.4.1-py3-none-any.whl.metadata (15 kB)\n",
            "Collecting torch~=2.7.0 (from invokeai==6.8.0)\n",
            "  Downloading torch-2.7.1-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (29 kB)\n",
            "Collecting torchsde (from invokeai==6.8.0)\n",
            "  Downloading torchsde-0.2.6-py3-none-any.whl.metadata (5.3 kB)\n",
            "Collecting torchvision (from invokeai==6.8.0)\n",
            "  Downloading torchvision-0.24.1-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (5.9 kB)\n",
            "Collecting transformers>=4.56.0 (from invokeai==6.8.0)\n",
            "  Downloading transformers-4.57.3-py3-none-any.whl.metadata (43 kB)\n",
            "Collecting fastapi-events (from invokeai==6.8.0)\n",
            "  Downloading fastapi_events-0.12.2-py3-none-any.whl.metadata (19 kB)\n",
            "Collecting fastapi (from invokeai==6.8.0)\n",
            "  Downloading fastapi-0.128.0-py3-none-any.whl.metadata (30 kB)\n",
            "Collecting huggingface-hub (from invokeai==6.8.0)\n",
            "  Downloading huggingface_hub-1.2.3-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting pydantic-settings (from invokeai==6.8.0)\n",
            "  Downloading pydantic_settings-2.12.0-py3-none-any.whl.metadata (3.4 kB)\n",
            "Collecting pydantic (from invokeai==6.8.0)\n",
            "  Downloading pydantic-2.12.5-py3-none-any.whl.metadata (90 kB)\n",
            "Collecting python-socketio (from invokeai==6.8.0)\n",
            "  Downloading python_socketio-5.16.0-py3-none-any.whl.metadata (3.2 kB)\n",
            "Collecting uvicorn[standard] (from invokeai==6.8.0)\n",
            "  Downloading uvicorn-0.40.0-py3-none-any.whl.metadata (6.7 kB)\n",
            "Collecting blake3 (from invokeai==6.8.0)\n",
            "  Downloading blake3-1.0.8-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.6 kB)\n",
            "Collecting Deprecated (from invokeai==6.8.0)\n",
            "  Downloading deprecated-1.3.1-py2.py3-none-any.whl.metadata (5.9 kB)\n",
            "Collecting dnspython (from invokeai==6.8.0)\n",
            "  Downloading dnspython-2.8.0-py3-none-any.whl.metadata (5.7 kB)\n",
            "Collecting dynamicprompts (from invokeai==6.8.0)\n",
            "  Downloading dynamicprompts-0.31.0-py3-none-any.whl.metadata (18 kB)\n",
            "Collecting einops (from invokeai==6.8.0)\n",
            "  Downloading einops-0.8.1-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting picklescan (from invokeai==6.8.0)\n",
            "  Downloading picklescan-0.0.34-py3-none-any.whl.metadata (6.5 kB)\n",
            "Collecting pillow (from invokeai==6.8.0)\n",
            "  Downloading pillow-12.1.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (8.8 kB)\n",
            "Collecting prompt-toolkit (from invokeai==6.8.0)\n",
            "  Downloading prompt_toolkit-3.0.52-py3-none-any.whl.metadata (6.4 kB)\n",
            "Collecting pypatchmatch (from invokeai==6.8.0)\n",
            "  Downloading PyPatchMatch-1.0.2-py3-none-any.whl.metadata (4.8 kB)\n",
            "Collecting python-multipart (from invokeai==6.8.0)\n",
            "  Downloading python_multipart-0.0.21-py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting requests (from invokeai==6.8.0)\n",
            "  Downloading requests-2.32.5-py3-none-any.whl.metadata (4.9 kB)\n",
            "Collecting semver~=3.0.1 (from invokeai==6.8.0)\n",
            "  Downloading semver-3.0.4-py3-none-any.whl.metadata (6.8 kB)\n",
            "Collecting PyWavelets (from invokeai==6.8.0)\n",
            "  Downloading pywavelets-1.9.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (7.6 kB)\n",
            "Collecting pyparsing~=3.0 (from compel==2.1.1->invokeai==6.8.0)\n",
            "  Downloading pyparsing-3.3.1-py3-none-any.whl.metadata (5.6 kB)\n",
            "Collecting importlib_metadata (from diffusers==0.33.0->diffusers[torch]==0.33.0->invokeai==6.8.0)\n",
            "  Downloading importlib_metadata-8.7.1-py3-none-any.whl.metadata (4.7 kB)\n",
            "Collecting filelock (from diffusers==0.33.0->diffusers[torch]==0.33.0->invokeai==6.8.0)\n",
            "  Downloading filelock-3.20.2-py3-none-any.whl.metadata (2.1 kB)\n",
            "Collecting regex!=2019.12.17 (from diffusers==0.33.0->diffusers[torch]==0.33.0->invokeai==6.8.0)\n",
            "  Downloading regex-2025.11.3-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (40 kB)\n",
            "Collecting absl-py (from mediapipe==0.10.14->invokeai==6.8.0)\n",
            "  Downloading absl_py-2.3.1-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting attrs>=19.1.0 (from mediapipe==0.10.14->invokeai==6.8.0)\n",
            "  Downloading attrs-25.4.0-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting flatbuffers>=2.0 (from mediapipe==0.10.14->invokeai==6.8.0)\n",
            "  Downloading flatbuffers-25.12.19-py2.py3-none-any.whl.metadata (1.0 kB)\n",
            "Collecting jax (from mediapipe==0.10.14->invokeai==6.8.0)\n",
            "  Downloading jax-0.8.2-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting jaxlib (from mediapipe==0.10.14->invokeai==6.8.0)\n",
            "  Downloading jaxlib-0.8.2-cp312-cp312-manylinux_2_27_x86_64.whl.metadata (1.3 kB)\n",
            "Collecting matplotlib (from mediapipe==0.10.14->invokeai==6.8.0)\n",
            "  Downloading matplotlib-3.10.8-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (52 kB)\n",
            "Collecting protobuf<5,>=4.25.3 (from mediapipe==0.10.14->invokeai==6.8.0)\n",
            "  Downloading protobuf-4.25.8-cp37-abi3-manylinux2014_x86_64.whl.metadata (541 bytes)\n",
            "Collecting sounddevice>=0.4.4 (from mediapipe==0.10.14->invokeai==6.8.0)\n",
            "  Downloading sounddevice-0.5.3-py3-none-any.whl.metadata (1.6 kB)\n",
            "Collecting coloredlogs (from onnxruntime==1.19.2->invokeai==6.8.0)\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Collecting packaging (from onnxruntime==1.19.2->invokeai==6.8.0)\n",
            "  Downloading packaging-25.0-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting sympy (from onnxruntime==1.19.2->invokeai==6.8.0)\n",
            "  Downloading sympy-1.14.0-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting typing-extensions>=4.10.0 (from torch~=2.7.0->invokeai==6.8.0)\n",
            "  Downloading typing_extensions-4.15.0-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting setuptools (from torch~=2.7.0->invokeai==6.8.0)\n",
            "  Downloading setuptools-80.9.0-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting networkx (from torch~=2.7.0->invokeai==6.8.0)\n",
            "  Downloading networkx-3.6.1-py3-none-any.whl.metadata (6.8 kB)\n",
            "Collecting jinja2 (from torch~=2.7.0->invokeai==6.8.0)\n",
            "  Downloading jinja2-3.1.6-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting fsspec (from torch~=2.7.0->invokeai==6.8.0)\n",
            "  Downloading fsspec-2025.12.0-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.6.77 (from torch~=2.7.0->invokeai==6.8.0)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.6.77-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.6.77 (from torch~=2.7.0->invokeai==6.8.0)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.6.80 (from torch~=2.7.0->invokeai==6.8.0)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.6.80-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.5.1.17 (from torch~=2.7.0->invokeai==6.8.0)\n",
            "  Downloading nvidia_cudnn_cu12-9.5.1.17-py3-none-manylinux_2_28_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.6.4.1 (from torch~=2.7.0->invokeai==6.8.0)\n",
            "  Downloading nvidia_cublas_cu12-12.6.4.1-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.3.0.4 (from torch~=2.7.0->invokeai==6.8.0)\n",
            "  Downloading nvidia_cufft_cu12-11.3.0.4-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.7.77 (from torch~=2.7.0->invokeai==6.8.0)\n",
            "  Downloading nvidia_curand_cu12-10.3.7.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.7.1.2 (from torch~=2.7.0->invokeai==6.8.0)\n",
            "  Downloading nvidia_cusolver_cu12-11.7.1.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.5.4.2 (from torch~=2.7.0->invokeai==6.8.0)\n",
            "  Downloading nvidia_cusparse_cu12-12.5.4.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparselt-cu12==0.6.3 (from torch~=2.7.0->invokeai==6.8.0)\n",
            "  Downloading nvidia_cusparselt_cu12-0.6.3-py3-none-manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
            "Collecting nvidia-nccl-cu12==2.26.2 (from torch~=2.7.0->invokeai==6.8.0)\n",
            "  Downloading nvidia_nccl_cu12-2.26.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.0 kB)\n",
            "Collecting nvidia-nvtx-cu12==12.6.77 (from torch~=2.7.0->invokeai==6.8.0)\n",
            "  Downloading nvidia_nvtx_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-nvjitlink-cu12==12.6.85 (from torch~=2.7.0->invokeai==6.8.0)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.6.85-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufile-cu12==1.11.1.6 (from torch~=2.7.0->invokeai==6.8.0)\n",
            "  Downloading nvidia_cufile_cu12-1.11.1.6-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting triton==3.3.1 (from torch~=2.7.0->invokeai==6.8.0)\n",
            "  Downloading triton-3.3.1-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting huggingface-hub (from invokeai==6.8.0)\n",
            "  Downloading huggingface_hub-0.36.0-py3-none-any.whl.metadata (14 kB)\n",
            "Collecting pyyaml>=5.1 (from transformers>=4.56.0->invokeai==6.8.0)\n",
            "  Downloading pyyaml-6.0.3-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (2.4 kB)\n",
            "Collecting tokenizers<=0.23.0,>=0.22.0 (from transformers>=4.56.0->invokeai==6.8.0)\n",
            "  Downloading tokenizers-0.22.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
            "Collecting tqdm>=4.27 (from transformers>=4.56.0->invokeai==6.8.0)\n",
            "  Downloading tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
            "Collecting hf-xet<2.0.0,>=1.1.3 (from huggingface-hub->invokeai==6.8.0)\n",
            "  Downloading hf_xet-1.2.0-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Collecting psutil (from accelerate->invokeai==6.8.0)\n",
            "  Downloading psutil-7.2.1-cp36-abi3-manylinux2010_x86_64.manylinux_2_12_x86_64.manylinux_2_28_x86_64.whl.metadata (22 kB)\n",
            "Collecting CFFI>=1.0 (from sounddevice>=0.4.4->mediapipe==0.10.14->invokeai==6.8.0)\n",
            "  Downloading cffi-2.0.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.6 kB)\n",
            "Collecting pycparser (from CFFI>=1.0->sounddevice>=0.4.4->mediapipe==0.10.14->invokeai==6.8.0)\n",
            "  Downloading pycparser-2.23-py3-none-any.whl.metadata (993 bytes)\n",
            "Collecting mpmath<1.4,>=1.1.0 (from sympy->onnxruntime==1.19.2->invokeai==6.8.0)\n",
            "  Downloading mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime==1.19.2->invokeai==6.8.0)\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
            "Collecting wrapt<3,>=1.10 (from Deprecated->invokeai==6.8.0)\n",
            "  Downloading wrapt-2.0.1-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl.metadata (9.0 kB)\n",
            "Collecting MarkupSafe>=2.0 (from jinja2->torch~=2.7.0->invokeai==6.8.0)\n",
            "  Downloading markupsafe-3.0.3-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (2.7 kB)\n",
            "Collecting starlette<0.51.0,>=0.40.0 (from fastapi->invokeai==6.8.0)\n",
            "  Downloading starlette-0.50.0-py3-none-any.whl.metadata (6.3 kB)\n",
            "Collecting annotated-doc>=0.0.2 (from fastapi->invokeai==6.8.0)\n",
            "  Downloading annotated_doc-0.0.4-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting anyio<5,>=3.6.2 (from starlette<0.51.0,>=0.40.0->fastapi->invokeai==6.8.0)\n",
            "  Downloading anyio-4.12.0-py3-none-any.whl.metadata (4.3 kB)\n",
            "Collecting idna>=2.8 (from anyio<5,>=3.6.2->starlette<0.51.0,>=0.40.0->fastapi->invokeai==6.8.0)\n",
            "  Downloading idna-3.11-py3-none-any.whl.metadata (8.4 kB)\n",
            "Collecting annotated-types>=0.6.0 (from pydantic->invokeai==6.8.0)\n",
            "  Downloading annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
            "Collecting pydantic-core==2.41.5 (from pydantic->invokeai==6.8.0)\n",
            "  Downloading pydantic_core-2.41.5-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.3 kB)\n",
            "Collecting typing-inspection>=0.4.2 (from pydantic->invokeai==6.8.0)\n",
            "  Downloading typing_inspection-0.4.2-py3-none-any.whl.metadata (2.6 kB)\n",
            "Collecting zipp>=3.20 (from importlib_metadata->diffusers==0.33.0->diffusers[torch]==0.33.0->invokeai==6.8.0)\n",
            "  Downloading zipp-3.23.0-py3-none-any.whl.metadata (3.6 kB)\n",
            "Collecting ml_dtypes>=0.5.0 (from jax->mediapipe==0.10.14->invokeai==6.8.0)\n",
            "  Downloading ml_dtypes-0.5.4-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (8.9 kB)\n",
            "INFO: pip is looking at multiple versions of jax to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting jax (from mediapipe==0.10.14->invokeai==6.8.0)\n",
            "  Downloading jax-0.8.1-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting jaxlib (from mediapipe==0.10.14->invokeai==6.8.0)\n",
            "  Downloading jaxlib-0.8.1-cp312-cp312-manylinux_2_27_x86_64.whl.metadata (1.3 kB)\n",
            "Collecting jax (from mediapipe==0.10.14->invokeai==6.8.0)\n",
            "  Downloading jax-0.8.0-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting jaxlib (from mediapipe==0.10.14->invokeai==6.8.0)\n",
            "  Downloading jaxlib-0.8.0-cp312-cp312-manylinux_2_27_x86_64.whl.metadata (1.3 kB)\n",
            "Collecting jax (from mediapipe==0.10.14->invokeai==6.8.0)\n",
            "  Downloading jax-0.7.2-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting jaxlib (from mediapipe==0.10.14->invokeai==6.8.0)\n",
            "  Downloading jaxlib-0.7.2-cp312-cp312-manylinux_2_27_x86_64.whl.metadata (1.3 kB)\n",
            "Collecting jax (from mediapipe==0.10.14->invokeai==6.8.0)\n",
            "  Downloading jax-0.7.1-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting jaxlib (from mediapipe==0.10.14->invokeai==6.8.0)\n",
            "  Downloading jaxlib-0.7.1-cp312-cp312-manylinux_2_27_x86_64.whl.metadata (1.3 kB)\n",
            "Collecting opt_einsum (from jax->mediapipe==0.10.14->invokeai==6.8.0)\n",
            "  Downloading opt_einsum-3.4.0-py3-none-any.whl.metadata (6.3 kB)\n",
            "Collecting scipy>=1.12 (from jax->mediapipe==0.10.14->invokeai==6.8.0)\n",
            "  Downloading scipy-1.16.3-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (62 kB)\n",
            "Collecting contourpy>=1.0.1 (from matplotlib->mediapipe==0.10.14->invokeai==6.8.0)\n",
            "  Downloading contourpy-1.3.3-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (5.5 kB)\n",
            "Collecting cycler>=0.10 (from matplotlib->mediapipe==0.10.14->invokeai==6.8.0)\n",
            "  Downloading cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
            "Collecting fonttools>=4.22.0 (from matplotlib->mediapipe==0.10.14->invokeai==6.8.0)\n",
            "  Downloading fonttools-4.61.1-cp312-cp312-manylinux1_x86_64.manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_5_x86_64.whl.metadata (114 kB)\n",
            "Collecting kiwisolver>=1.3.1 (from matplotlib->mediapipe==0.10.14->invokeai==6.8.0)\n",
            "  Downloading kiwisolver-1.4.9-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (6.3 kB)\n",
            "Collecting python-dateutil>=2.7 (from matplotlib->mediapipe==0.10.14->invokeai==6.8.0)\n",
            "  Downloading python_dateutil-2.9.0.post0-py2.py3-none-any.whl.metadata (8.4 kB)\n",
            "Collecting six>=1.5 (from python-dateutil>=2.7->matplotlib->mediapipe==0.10.14->invokeai==6.8.0)\n",
            "  Downloading six-1.17.0-py2.py3-none-any.whl.metadata (1.7 kB)\n",
            "INFO: pip is looking at multiple versions of opencv-contrib-python to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting opencv-contrib-python (from invokeai==6.8.0)\n",
            "  Downloading opencv_contrib_python-4.11.0.86-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
            "Collecting wcwidth (from prompt-toolkit->invokeai==6.8.0)\n",
            "  Downloading wcwidth-0.2.14-py2.py3-none-any.whl.metadata (15 kB)\n",
            "Collecting python-dotenv>=0.21.0 (from pydantic-settings->invokeai==6.8.0)\n",
            "  Downloading python_dotenv-1.2.1-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting bidict>=0.21.0 (from python-socketio->invokeai==6.8.0)\n",
            "  Downloading bidict-0.23.1-py3-none-any.whl.metadata (8.7 kB)\n",
            "Collecting python-engineio>=4.11.0 (from python-socketio->invokeai==6.8.0)\n",
            "  Downloading python_engineio-4.13.0-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting simple-websocket>=0.10.0 (from python-engineio>=4.11.0->python-socketio->invokeai==6.8.0)\n",
            "  Downloading simple_websocket-1.1.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting wsproto (from simple-websocket>=0.10.0->python-engineio>=4.11.0->python-socketio->invokeai==6.8.0)\n",
            "  Downloading wsproto-1.3.2-py3-none-any.whl.metadata (5.2 kB)\n",
            "Collecting charset_normalizer<4,>=2 (from requests->invokeai==6.8.0)\n",
            "  Downloading charset_normalizer-3.4.4-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (37 kB)\n",
            "Collecting urllib3<3,>=1.21.1 (from requests->invokeai==6.8.0)\n",
            "  Downloading urllib3-2.6.2-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting certifi>=2017.4.17 (from requests->invokeai==6.8.0)\n",
            "  Downloading certifi-2025.11.12-py3-none-any.whl.metadata (2.5 kB)\n",
            "Collecting trampoline>=0.1.2 (from torchsde->invokeai==6.8.0)\n",
            "  Downloading trampoline-0.1.2-py3-none-any.whl.metadata (10 kB)\n",
            "INFO: pip is looking at multiple versions of torchvision to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting torchvision (from invokeai==6.8.0)\n",
            "  Downloading torchvision-0.24.0-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (5.9 kB)\n",
            "  Downloading torchvision-0.23.0-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (6.1 kB)\n",
            "  Downloading torchvision-0.22.1-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (6.1 kB)\n",
            "Collecting click>=7.0 (from uvicorn[standard]->invokeai==6.8.0)\n",
            "  Downloading click-8.3.1-py3-none-any.whl.metadata (2.6 kB)\n",
            "Collecting h11>=0.8 (from uvicorn[standard]->invokeai==6.8.0)\n",
            "  Downloading h11-0.16.0-py3-none-any.whl.metadata (8.3 kB)\n",
            "Collecting httptools>=0.6.3 (from uvicorn[standard]->invokeai==6.8.0)\n",
            "  Downloading httptools-0.7.1-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl.metadata (3.5 kB)\n",
            "Collecting uvloop>=0.15.1 (from uvicorn[standard]->invokeai==6.8.0)\n",
            "  Downloading uvloop-0.22.1-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (4.9 kB)\n",
            "Collecting watchfiles>=0.13 (from uvicorn[standard]->invokeai==6.8.0)\n",
            "  Downloading watchfiles-1.1.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Collecting websockets>=10.4 (from uvicorn[standard]->invokeai==6.8.0)\n",
            "  Downloading websockets-15.0.1-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
            "Downloading invokeai-6.8.0-py3-none-any.whl (9.3 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m9.3/9.3 MB\u001b[0m \u001b[31m146.9 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading compel-2.1.1-py3-none-any.whl (31 kB)\n",
            "Downloading diffusers-0.33.0-py3-none-any.whl (3.6 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m128.6 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mediapipe-0.10.14-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (35.7 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m35.7/35.7 MB\u001b[0m \u001b[31m62.5 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading onnx-1.16.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (15.9 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m15.9/15.9 MB\u001b[0m \u001b[31m137.7 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading onnxruntime-1.19.2-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (13.2 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m13.2/13.2 MB\u001b[0m \u001b[31m134.0 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading sentencepiece-0.2.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m59.6 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-1.26.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.0 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m18.0/18.0 MB\u001b[0m \u001b[31m148.7 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading protobuf-4.25.8-cp37-abi3-manylinux2014_x86_64.whl (294 kB)\n",
            "Downloading pyparsing-3.3.1-py3-none-any.whl (121 kB)\n",
            "Downloading semver-3.0.4-py3-none-any.whl (17 kB)\n",
            "Downloading torch-2.7.1-cp312-cp312-manylinux_2_28_x86_64.whl (821.0 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m821.0/821.0 MB\u001b[0m \u001b[31m21.0 MB/s\u001b[0m  \u001b[33m0:00:18\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.6.4.1-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (393.1 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m393.1/393.1 MB\u001b[0m \u001b[31m50.9 MB/s\u001b[0m  \u001b[33m0:00:05\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.6.80-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (8.9 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m8.9/8.9 MB\u001b[0m \u001b[31m178.3 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.6.77-py3-none-manylinux2014_x86_64.whl (23.7 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m197.5 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (897 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m897.7/897.7 kB\u001b[0m \u001b[31m48.9 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.5.1.17-py3-none-manylinux_2_28_x86_64.whl (571.0 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m571.0/571.0 MB\u001b[0m \u001b[31m41.3 MB/s\u001b[0m  \u001b[33m0:00:09\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.3.0.4-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (200.2 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m200.2/200.2 MB\u001b[0m \u001b[31m26.7 MB/s\u001b[0m  \u001b[33m0:00:07\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufile_cu12-1.11.1.6-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m59.6 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.7.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m63.7 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.7.1.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (158.2 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m158.2/158.2 MB\u001b[0m \u001b[31m70.4 MB/s\u001b[0m  \u001b[33m0:00:02\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.5.4.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (216.6 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m216.6/216.6 MB\u001b[0m \u001b[31m71.5 MB/s\u001b[0m  \u001b[33m0:00:03\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparselt_cu12-0.6.3-py3-none-manylinux2014_x86_64.whl (156.8 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m156.8/156.8 MB\u001b[0m \u001b[31m71.0 MB/s\u001b[0m  \u001b[33m0:00:02\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nccl_cu12-2.26.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (201.3 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m201.3/201.3 MB\u001b[0m \u001b[31m72.2 MB/s\u001b[0m  \u001b[33m0:00:02\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.6.85-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (19.7 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m19.7/19.7 MB\u001b[0m \u001b[31m202.9 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvtx_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (89 kB)\n",
            "Downloading triton-3.3.1-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (155.7 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m155.7/155.7 MB\u001b[0m \u001b[31m68.5 MB/s\u001b[0m  \u001b[33m0:00:02\u001b[0m\n",
            "\u001b[?25hDownloading transformers-4.57.3-py3-none-any.whl (12.0 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m12.0/12.0 MB\u001b[0m \u001b[31m136.6 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading huggingface_hub-0.36.0-py3-none-any.whl (566 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m566.1/566.1 kB\u001b[0m \u001b[31m24.1 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading hf_xet-1.2.0-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m111.5 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tokenizers-0.22.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m124.7 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading accelerate-1.12.0-py3-none-any.whl (380 kB)\n",
            "Downloading attrs-25.4.0-py3-none-any.whl (67 kB)\n",
            "Downloading flatbuffers-25.12.19-py2.py3-none-any.whl (26 kB)\n",
            "Downloading fsspec-2025.12.0-py3-none-any.whl (201 kB)\n",
            "Downloading packaging-25.0-py3-none-any.whl (66 kB)\n",
            "Downloading pyyaml-6.0.3-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (807 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m807.9/807.9 kB\u001b[0m \u001b[31m46.8 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading regex-2025.11.3-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (803 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m803.5/803.5 kB\u001b[0m \u001b[31m42.4 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading safetensors-0.7.0-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (507 kB)\n",
            "Downloading setuptools-80.9.0-py3-none-any.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m68.3 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading sounddevice-0.5.3-py3-none-any.whl (32 kB)\n",
            "Downloading cffi-2.0.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (219 kB)\n",
            "Downloading sympy-1.14.0-py3-none-any.whl (6.3 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m160.5 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m536.2/536.2 kB\u001b[0m \u001b[31m26.0 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
            "Downloading typing_extensions-4.15.0-py3-none-any.whl (44 kB)\n",
            "Downloading absl_py-2.3.1-py3-none-any.whl (135 kB)\n",
            "Downloading bitsandbytes-0.49.0-py3-none-manylinux_2_24_x86_64.whl (59.1 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m59.1/59.1 MB\u001b[0m \u001b[31m76.0 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading blake3-1.0.8-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (388 kB)\n",
            "Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "Downloading deprecated-1.3.1-py2.py3-none-any.whl (11 kB)\n",
            "Downloading wrapt-2.0.1-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl (121 kB)\n",
            "Downloading dnspython-2.8.0-py3-none-any.whl (331 kB)\n",
            "Downloading dynamicprompts-0.31.0-py3-none-any.whl (53 kB)\n",
            "Downloading jinja2-3.1.6-py3-none-any.whl (134 kB)\n",
            "Downloading markupsafe-3.0.3-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (22 kB)\n",
            "Downloading einops-0.8.1-py3-none-any.whl (64 kB)\n",
            "Downloading fastapi-0.128.0-py3-none-any.whl (103 kB)\n",
            "Downloading starlette-0.50.0-py3-none-any.whl (74 kB)\n",
            "Downloading anyio-4.12.0-py3-none-any.whl (113 kB)\n",
            "Downloading annotated_doc-0.0.4-py3-none-any.whl (5.3 kB)\n",
            "Downloading idna-3.11-py3-none-any.whl (71 kB)\n",
            "Downloading pydantic-2.12.5-py3-none-any.whl (463 kB)\n",
            "Downloading pydantic_core-2.41.5-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m107.0 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
            "Downloading typing_inspection-0.4.2-py3-none-any.whl (14 kB)\n",
            "Downloading fastapi_events-0.12.2-py3-none-any.whl (28 kB)\n",
            "Downloading filelock-3.20.2-py3-none-any.whl (16 kB)\n",
            "Downloading gguf-0.17.1-py3-none-any.whl (96 kB)\n",
            "Downloading importlib_metadata-8.7.1-py3-none-any.whl (27 kB)\n",
            "Downloading zipp-3.23.0-py3-none-any.whl (10 kB)\n",
            "Downloading jax-0.7.1-py3-none-any.whl (2.8 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.8/2.8 MB\u001b[0m \u001b[31m118.1 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jaxlib-0.7.1-cp312-cp312-manylinux_2_27_x86_64.whl (81.2 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m81.2/81.2 MB\u001b[0m \u001b[31m60.6 MB/s\u001b[0m  \u001b[33m0:00:01\u001b[0m\n",
            "\u001b[?25hDownloading ml_dtypes-0.5.4-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (5.0 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m5.0/5.0 MB\u001b[0m \u001b[31m127.7 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading scipy-1.16.3-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (35.7 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m35.7/35.7 MB\u001b[0m \u001b[31m116.0 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading matplotlib-3.10.8-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (8.7 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m8.7/8.7 MB\u001b[0m \u001b[31m138.1 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading contourpy-1.3.3-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (362 kB)\n",
            "Downloading cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
            "Downloading fonttools-4.61.1-cp312-cp312-manylinux1_x86_64.manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_5_x86_64.whl (5.0 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m5.0/5.0 MB\u001b[0m \u001b[31m111.3 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading kiwisolver-1.4.9-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (1.5 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m63.7 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pillow-12.1.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (7.0 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m128.1 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_dateutil-2.9.0.post0-py2.py3-none-any.whl (229 kB)\n",
            "Downloading six-1.17.0-py2.py3-none-any.whl (11 kB)\n",
            "Downloading networkx-3.6.1-py3-none-any.whl (2.1 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m89.5 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opencv_contrib_python-4.11.0.86-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (69.1 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m69.1/69.1 MB\u001b[0m \u001b[31m52.6 MB/s\u001b[0m  \u001b[33m0:00:01\u001b[0m\n",
            "\u001b[?25hDownloading opt_einsum-3.4.0-py3-none-any.whl (71 kB)\n",
            "Downloading picklescan-0.0.34-py3-none-any.whl (21 kB)\n",
            "Downloading prompt_toolkit-3.0.52-py3-none-any.whl (391 kB)\n",
            "Downloading psutil-7.2.1-cp36-abi3-manylinux2010_x86_64.manylinux_2_12_x86_64.manylinux_2_28_x86_64.whl (154 kB)\n",
            "Downloading pycparser-2.23-py3-none-any.whl (118 kB)\n",
            "Downloading pydantic_settings-2.12.0-py3-none-any.whl (51 kB)\n",
            "Downloading python_dotenv-1.2.1-py3-none-any.whl (21 kB)\n",
            "Downloading PyPatchMatch-1.0.2-py3-none-any.whl (20 kB)\n",
            "Downloading python_multipart-0.0.21-py3-none-any.whl (24 kB)\n",
            "Downloading python_socketio-5.16.0-py3-none-any.whl (79 kB)\n",
            "Downloading bidict-0.23.1-py3-none-any.whl (32 kB)\n",
            "Downloading python_engineio-4.13.0-py3-none-any.whl (59 kB)\n",
            "Downloading simple_websocket-1.1.0-py3-none-any.whl (13 kB)\n",
            "Downloading pywavelets-1.9.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (4.5 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m110.6 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading requests-2.32.5-py3-none-any.whl (64 kB)\n",
            "Downloading charset_normalizer-3.4.4-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (153 kB)\n",
            "Downloading urllib3-2.6.2-py3-none-any.whl (131 kB)\n",
            "Downloading certifi-2025.11.12-py3-none-any.whl (159 kB)\n",
            "Downloading spandrel-0.4.1-py3-none-any.whl (305 kB)\n",
            "Downloading torchsde-0.2.6-py3-none-any.whl (61 kB)\n",
            "Downloading trampoline-0.1.2-py3-none-any.whl (5.2 kB)\n",
            "Downloading torchvision-0.22.1-cp312-cp312-manylinux_2_28_x86_64.whl (7.5 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m7.5/7.5 MB\u001b[0m \u001b[31m105.5 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading uvicorn-0.40.0-py3-none-any.whl (68 kB)\n",
            "Downloading click-8.3.1-py3-none-any.whl (108 kB)\n",
            "Downloading h11-0.16.0-py3-none-any.whl (37 kB)\n",
            "Downloading httptools-0.7.1-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl (517 kB)\n",
            "Downloading uvloop-0.22.1-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (4.4 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m4.4/4.4 MB\u001b[0m \u001b[31m122.0 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading watchfiles-1.1.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (456 kB)\n",
            "Downloading websockets-15.0.1-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (182 kB)\n",
            "Downloading wcwidth-0.2.14-py2.py3-none-any.whl (37 kB)\n",
            "Downloading wsproto-1.3.2-py3-none-any.whl (24 kB)\n",
            "Installing collected packages: trampoline, sentencepiece, nvidia-cusparselt-cu12, mpmath, flatbuffers, zipp, wrapt, websockets, wcwidth, uvloop, urllib3, typing-extensions, tqdm, sympy, six, setuptools, semver, safetensors, regex, pyyaml, python-multipart, python-dotenv, pyparsing, pycparser, psutil, protobuf, pillow, picklescan, packaging, opt_einsum, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufile-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, numpy, networkx, MarkupSafe, kiwisolver, idna, humanfriendly, httptools, hf-xet, h11, fsspec, fonttools, filelock, fastapi-events, einops, dnspython, cycler, click, charset_normalizer, certifi, blake3, bidict, attrs, annotated-types, annotated-doc, absl-py, wsproto, uvicorn, typing-inspection, triton, scipy, requests, PyWavelets, python-dateutil, pypatchmatch, pydantic-core, prompt-toolkit, opencv-contrib-python, onnx, nvidia-cusparse-cu12, nvidia-cufft-cu12, nvidia-cudnn-cu12, ml_dtypes, jinja2, importlib_metadata, gguf, Deprecated, contourpy, coloredlogs, CFFI, anyio, watchfiles, starlette, sounddevice, simple-websocket, pydantic, onnxruntime, nvidia-cusolver-cu12, matplotlib, jaxlib, huggingface-hub, dynamicprompts, torch, tokenizers, python-engineio, pydantic-settings, jax, fastapi, diffusers, transformers, torchvision, torchsde, python-socketio, mediapipe, bitsandbytes, accelerate, spandrel, compel, invokeai\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m117/117\u001b[0m [invokeai]\n",
            "\u001b[1A\u001b[2KSuccessfully installed CFFI-2.0.0 Deprecated-1.3.1 MarkupSafe-3.0.3 PyWavelets-1.9.0 absl-py-2.3.1 accelerate-1.12.0 annotated-doc-0.0.4 annotated-types-0.7.0 anyio-4.12.0 attrs-25.4.0 bidict-0.23.1 bitsandbytes-0.49.0 blake3-1.0.8 certifi-2025.11.12 charset_normalizer-3.4.4 click-8.3.1 coloredlogs-15.0.1 compel-2.1.1 contourpy-1.3.3 cycler-0.12.1 diffusers-0.33.0 dnspython-2.8.0 dynamicprompts-0.31.0 einops-0.8.1 fastapi-0.128.0 fastapi-events-0.12.2 filelock-3.20.2 flatbuffers-25.12.19 fonttools-4.61.1 fsspec-2025.12.0 gguf-0.17.1 h11-0.16.0 hf-xet-1.2.0 httptools-0.7.1 huggingface-hub-0.36.0 humanfriendly-10.0 idna-3.11 importlib_metadata-8.7.1 invokeai-6.8.0 jax-0.7.1 jaxlib-0.7.1 jinja2-3.1.6 kiwisolver-1.4.9 matplotlib-3.10.8 mediapipe-0.10.14 ml_dtypes-0.5.4 mpmath-1.3.0 networkx-3.6.1 numpy-1.26.4 nvidia-cublas-cu12-12.6.4.1 nvidia-cuda-cupti-cu12-12.6.80 nvidia-cuda-nvrtc-cu12-12.6.77 nvidia-cuda-runtime-cu12-12.6.77 nvidia-cudnn-cu12-9.5.1.17 nvidia-cufft-cu12-11.3.0.4 nvidia-cufile-cu12-1.11.1.6 nvidia-curand-cu12-10.3.7.77 nvidia-cusolver-cu12-11.7.1.2 nvidia-cusparse-cu12-12.5.4.2 nvidia-cusparselt-cu12-0.6.3 nvidia-nccl-cu12-2.26.2 nvidia-nvjitlink-cu12-12.6.85 nvidia-nvtx-cu12-12.6.77 onnx-1.16.1 onnxruntime-1.19.2 opencv-contrib-python-4.11.0.86 opt_einsum-3.4.0 packaging-25.0 picklescan-0.0.34 pillow-12.1.0 prompt-toolkit-3.0.52 protobuf-4.25.8 psutil-7.2.1 pycparser-2.23 pydantic-2.12.5 pydantic-core-2.41.5 pydantic-settings-2.12.0 pyparsing-3.3.1 pypatchmatch-1.0.2 python-dateutil-2.9.0.post0 python-dotenv-1.2.1 python-engineio-4.13.0 python-multipart-0.0.21 python-socketio-5.16.0 pyyaml-6.0.3 regex-2025.11.3 requests-2.32.5 safetensors-0.7.0 scipy-1.16.3 semver-3.0.4 sentencepiece-0.2.0 setuptools-80.9.0 simple-websocket-1.1.0 six-1.17.0 sounddevice-0.5.3 spandrel-0.4.1 starlette-0.50.0 sympy-1.14.0 tokenizers-0.22.1 torch-2.7.1 torchsde-0.2.6 torchvision-0.22.1 tqdm-4.67.1 trampoline-0.1.2 transformers-4.57.3 triton-3.3.1 typing-extensions-4.15.0 typing-inspection-0.4.2 urllib3-2.6.2 uvicorn-0.40.0 uvloop-0.22.1 watchfiles-1.1.1 wcwidth-0.2.14 websockets-15.0.1 wrapt-2.0.1 wsproto-1.3.2 zipp-3.23.0\n",
            "âœ… Invoke 6.8.0 instalado correctamente.\n",
            "Selecting previously unselected package cloudflared.\n",
            "(Reading database ... 121689 files and directories currently installed.)\n",
            "Preparing to unpack cloudflared-linux-amd64.deb ...\n",
            "Unpacking cloudflared (2025.11.1) ...\n",
            "Setting up cloudflared (2025.11.1) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "âœ… Cloudflared instalado correctamente.\n",
            "----------------------------------------\n",
            "âœ… BLOQUE 2 completado con Ã©xito. â¡ï¸ Ejecuta el BLOQUE 3 para lanzar la interfaz.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown ## âš¡Modo Low VRAM (Opcional)\n",
        "#@markdown\n",
        "#@markdown > Ejecuta este bloque si quieres activar el modo LoW VRAM (Recomendado)\n",
        "\n",
        "import os\n",
        "\n",
        "config_path = \"/root/invokeai/invokeai.yaml\"\n",
        "\n",
        "# Crear carpeta si no existe\n",
        "os.makedirs(os.path.dirname(config_path), exist_ok=True)\n",
        "\n",
        "# Crear archivo con contenido completo\n",
        "with open(config_path, \"w\") as f:\n",
        "    f.write(\n",
        "\"\"\"# Internal metadata - do not edit:\n",
        "schema_version: 4.0.2\n",
        "\n",
        "# Put user settings here - see https://invoke-ai.github.io/InvokeAI/configuration/:\n",
        "enable_partial_loading: true\n",
        "\"\"\"\n",
        "    )\n",
        "\n",
        "print(f\"âœ”ï¸ Archivo creado en {config_path}\")\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "ipHZjdrJhe7G",
        "outputId": "4902cc15-0f25-4935-edc1-1496448fc81f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ”ï¸ Archivo creado en /root/invokeai/invokeai.yaml\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown ## ğŸš€ BLOQUE 3 â€“ Iniciar interfaz web de Invoke AI\n",
        "#@markdown\n",
        "#@markdown > Este es el Ãºltimo paso: crearemos el tÃºnel de acceso y lanzaremos la interfaz de Invoke.<br>\n",
        "#@markdown > ğŸŸ¢Cuando veas que aparece la direcciÃ³n `127.0.0.1:9090` <br>\n",
        "#@markdown > &nbsp; &nbsp; &nbsp;pulsa en el enlace tipo `https://xxx.trycloudflare.com` que aparece encima.<br><br>\n",
        "#@markdown > ğŸ”— Ãbrelo en una nueva pestaÃ±a para empezar a crear imÃ¡genes.  <br>\n",
        "\n",
        "# ğŸš€ BLOQUE 3 â€“ Iniciar Invoke AI Web UI con tÃºnel Cloudflare\n",
        "# Iniciamos el tÃºnel de Cloudflare en segundo plano\n",
        "import threading\n",
        "\n",
        "def start_tunnel():\n",
        "  !cloudflared tunnel --url http://localhost:9090 &\n",
        "\n",
        "threading.Thread(target=start_tunnel, daemon=True).start()\n",
        "\n",
        "# Forzamos el backend de matplotlib para evitar errores en entornos sin interfaz\n",
        "import matplotlib\n",
        "matplotlib.use('Agg')\n",
        "\n",
        "# Lanzamos la interfaz web de Invoke AI con backend Agg forzado\n",
        "!MPLBACKEND=Agg .venv/bin/invokeai-web --root ~/invokeai\n",
        "\n",
        "print(\"----------------------------------------\")\n",
        "print(\"âœ… BLOQUE 3 completado con Ã©xito. â¡ï¸ Lanza la interfaz y empieza a crear!\")"
      ],
      "metadata": {
        "id": "vSqcSifaE_fY",
        "cellView": "form",
        "outputId": "80c70037-f7b7-44fa-e38b-dc2e9ad1e8ef",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[90m2026-01-02T17:23:43Z\u001b[0m \u001b[32mINF\u001b[0m Thank you for trying Cloudflare Tunnel. Doing so, without a Cloudflare account, is a quick way to experiment and try it out. However, be aware that these account-less Tunnels have no uptime guarantee, are subject to the Cloudflare Online Services Terms of Use (https://www.cloudflare.com/website-terms/), and Cloudflare reserves the right to investigate your use of Tunnels for violations of such terms. If you intend to use Tunnels in production you should use a pre-created named tunnel by following: https://developers.cloudflare.com/cloudflare-one/connections/connect-apps\n",
            "\u001b[90m2026-01-02T17:23:43Z\u001b[0m \u001b[32mINF\u001b[0m Requesting new quick Tunnel on trycloudflare.com...\n",
            "\u001b[90m2026-01-02T17:23:46Z\u001b[0m \u001b[32mINF\u001b[0m +--------------------------------------------------------------------------------------------+\n",
            "\u001b[90m2026-01-02T17:23:46Z\u001b[0m \u001b[32mINF\u001b[0m |  Your quick Tunnel has been created! Visit it at (it may take some time to be reachable):  |\n",
            "\u001b[90m2026-01-02T17:23:46Z\u001b[0m \u001b[32mINF\u001b[0m |  https://wallet-mixed-radios-mike.trycloudflare.com                                        |\n",
            "\u001b[90m2026-01-02T17:23:46Z\u001b[0m \u001b[32mINF\u001b[0m +--------------------------------------------------------------------------------------------+\n",
            "\u001b[90m2026-01-02T17:23:46Z\u001b[0m \u001b[32mINF\u001b[0m Cannot determine default configuration path. No file [config.yml config.yaml] in [~/.cloudflared ~/.cloudflare-warp ~/cloudflare-warp /etc/cloudflared /usr/local/etc/cloudflared]\n",
            "\u001b[90m2026-01-02T17:23:46Z\u001b[0m \u001b[32mINF\u001b[0m Version 2025.11.1 (Checksum 83ea55259e419549817460d0c097f23ad1327364d0a63fab2c5463b9283251cb)\n",
            "\u001b[90m2026-01-02T17:23:46Z\u001b[0m \u001b[32mINF\u001b[0m GOOS: linux, GOVersion: go1.24.9, GoArch: amd64\n",
            "\u001b[90m2026-01-02T17:23:46Z\u001b[0m \u001b[32mINF\u001b[0m Settings: map[ha-connections:1 protocol:quic url:http://localhost:9090]\n",
            "\u001b[90m2026-01-02T17:23:46Z\u001b[0m \u001b[32mINF\u001b[0m Generated Connector ID: f950c5a8-f620-4fb8-8e73-875fc91a8688\n",
            "\u001b[90m2026-01-02T17:23:46Z\u001b[0m \u001b[32mINF\u001b[0m cloudflared will not automatically update if installed by a package manager.\n",
            "\u001b[90m2026-01-02T17:23:46Z\u001b[0m \u001b[32mINF\u001b[0m Initial protocol quic\n",
            "\u001b[90m2026-01-02T17:23:46Z\u001b[0m \u001b[32mINF\u001b[0m ICMP proxy will use 172.28.0.12 as source for IPv4\n",
            "\u001b[90m2026-01-02T17:23:46Z\u001b[0m \u001b[32mINF\u001b[0m ICMP proxy will use ::1 in zone lo as source for IPv6\n",
            "\u001b[90m2026-01-02T17:23:46Z\u001b[0m \u001b[1m\u001b[31mERR\u001b[0m\u001b[0m Cannot determine default origin certificate path. No file cert.pem in [~/.cloudflared ~/.cloudflare-warp ~/cloudflare-warp /etc/cloudflared /usr/local/etc/cloudflared]. You need to specify the origin certificate path by specifying the origincert option in the configuration file, or set TUNNEL_ORIGIN_CERT environment variable \u001b[36moriginCertPath=\u001b[0m\n",
            "\u001b[90m2026-01-02T17:23:46Z\u001b[0m \u001b[32mINF\u001b[0m ICMP proxy will use 172.28.0.12 as source for IPv4\n",
            "\u001b[90m2026-01-02T17:23:46Z\u001b[0m \u001b[32mINF\u001b[0m ICMP proxy will use ::1 in zone lo as source for IPv6\n",
            "\u001b[90m2026-01-02T17:23:46Z\u001b[0m \u001b[32mINF\u001b[0m Starting metrics server on 127.0.0.1:20241/metrics\n",
            "\u001b[90m2026-01-02T17:23:46Z\u001b[0m \u001b[32mINF\u001b[0m Tunnel connection curve preferences: [X25519MLKEM768 CurveP256] \u001b[36mconnIndex=\u001b[0m0 \u001b[36mevent=\u001b[0m0 \u001b[36mip=\u001b[0m198.41.192.7\n",
            "2026/01/02 17:23:46 failed to sufficiently increase receive buffer size (was: 208 kiB, wanted: 7168 kiB, got: 416 kiB). See https://github.com/quic-go/quic-go/wiki/UDP-Buffer-Sizes for details.\n",
            "\u001b[90m2026-01-02T17:23:47Z\u001b[0m \u001b[32mINF\u001b[0m Registered tunnel connection \u001b[36mconnIndex=\u001b[0m0 \u001b[36mconnection=\u001b[0m59f849d4-0804-4e35-8eb2-8ee3aca2180e \u001b[36mevent=\u001b[0m0 \u001b[36mip=\u001b[0m198.41.192.7 \u001b[36mlocation=\u001b[0msin21 \u001b[36mprotocol=\u001b[0mquic\n",
            "\u001b[38;20m[2026-01-02 17:24:02,129]::[InvokeAI]::INFO --> Using torch device: Tesla T4\u001b[0m\n",
            "\u001b[38;20m[2026-01-02 17:24:02,166]::[InvokeAI]::INFO --> cuDNN version: 90501\u001b[0m\n",
            ">> patchmatch.patch_match: INFO - Compiling and loading c extensions from \"/root/invokeai/.venv/lib/python3.12/site-packages/patchmatch\".\n",
            ">> patchmatch.patch_match: ERROR - patchmatch failed to load or compile (Command 'make clean && make' returned non-zero exit status 2.).\n",
            ">> patchmatch.patch_match: INFO - Refer to https://invoke-ai.github.io/InvokeAI/installation/060_INSTALL_PATCHMATCH/ for installation instructions.\n",
            "\u001b[38;20m[2026-01-02 17:24:05,247]::[InvokeAI]::INFO --> Patchmatch not loaded (nonfatal)\u001b[0m\n",
            "\u001b[38;20m[2026-01-02 17:24:06,013]::[InvokeAI]::INFO --> InvokeAI version 6.8.0\u001b[0m\n",
            "\u001b[38;20m[2026-01-02 17:24:06,013]::[InvokeAI]::INFO --> Root directory = /root/invokeai\u001b[0m\n",
            "\u001b[38;20m[2026-01-02 17:24:06,014]::[InvokeAI]::INFO --> Initializing database at /root/invokeai/databases/invokeai.db\u001b[0m\n",
            "\u001b[38;20m[2026-01-02 17:24:06,039]::[InvokeAI]::INFO --> Database update needed\u001b[0m\n",
            "\u001b[38;20m[2026-01-02 17:24:06,039]::[InvokeAI]::INFO --> Backing up database to /root/invokeai/databases/invokeai_backup_20260102-172406.db\u001b[0m\n",
            "\u001b[38;20m[2026-01-02 17:24:06,308]::[InvokeAI]::INFO --> Removing models/.cache directory. Converted models will now be cached in .convert_cache.\u001b[0m\n",
            "\u001b[38;20m[2026-01-02 17:24:06,308]::[InvokeAI]::INFO --> Removing legacy just-in-time models. Downloaded models will now be cached in .download_cache.\u001b[0m\n",
            "\u001b[38;20m[2026-01-02 17:24:06,309]::[InvokeAI]::INFO --> Removing defunct core models.\u001b[0m\n",
            "\u001b[38;20m[2026-01-02 17:24:06,403]::[InvokeAI]::INFO --> Database updated successfully\u001b[0m\n",
            "\u001b[38;20m[2026-01-02 17:24:06,639]::[ModelManagerService]::INFO --> [MODEL CACHE] Calculated model RAM cache size: 4439.78 MB. Heuristics applied: [1].\u001b[0m\n",
            "\u001b[38;20m[2026-01-02 17:24:06,723]::[InvokeAI]::INFO --> Invoke running on http://127.0.0.1:9090 (Press CTRL+C to quit)\u001b[0m\n",
            "/root/invokeai/.venv/lib/python3.12/site-packages/huggingface_hub/utils/_deprecation.py:131: FutureWarning: 'get_token_permission' (from 'huggingface_hub.hf_api') is deprecated and will be removed from version '1.0'. Permissions are more complex than when `get_token_permission` was first introduced. OAuth and fine-grain tokens allows for more detailed permissions. If you need to know the permissions associated with a token, please use `whoami` and check the `'auth'` key.\n",
            "  warnings.warn(warning_message, FutureWarning)\n",
            "\u001b[38;20m[2026-01-02 17:41:59,713]::[ModelInstallService]::INFO --> Queueing model install: https://civitai.com/api/download/models/2462789?type=Model&format=SafeTensor&size=pruned&fp=fp16 (1 file)\u001b[0m\n",
            "\u001b[38;20m[2026-01-02 17:41:59,713]::[InvokeAI]::INFO --> Started installation of https://civitai.com/api/download/models/2462789?type=Model&format=SafeTensor&size=pruned&fp=fp16\u001b[0m\n",
            "\u001b[38;20m[2026-01-02 17:42:02,015]::[DownloadQueueService]::INFO --> File download started: https://civitai.com/api/download/models/2462789?type=Model&format=SafeTensor&size=pruned&fp=fp16\u001b[0m\n",
            "\u001b[38;20m[2026-01-02 17:42:14,291]::[DownloadQueueService]::INFO --> Download complete: https://civitai.com/api/download/models/2462789?type=Model&format=SafeTensor&size=pruned&fp=fp16\u001b[0m\n",
            "\u001b[38;20m[2026-01-02 17:42:14,291]::[ModelInstallService]::INFO --> Model download complete: https://civitai.com/api/download/models/2462789?type=Model&format=SafeTensor&size=pruned&fp=fp16\u001b[0m\n",
            "\u001b[38;20m[2026-01-02 17:42:14,292]::[ModelInstallService]::INFO --> Model install started: https://civitai.com/api/download/models/2462789?type=Model&format=SafeTensor&size=pruned&fp=fp16\u001b[0m\n",
            "\u001b[31;20m[2026-01-02 17:42:14,364]::[ModelInstallService]::ERROR --> Model install error: https://civitai.com/api/download/models/2462789?type=Model&format=SafeTensor&size=pruned&fp=fp16\n",
            "InvalidModelConfigException: Unable to determine model type\u001b[0m\n",
            "\u001b[38;20m[2026-01-02 17:43:22,503]::[ModelInstallService]::INFO --> Queueing model install: https://huggingface.co/jerryytq/redcraftRedzimageUpdatedDEC03_redzimage15AIO/resolve/main/redcraftRedzimageUpdatedDEC03_redzimage15AIO.safetensors (1 file)\u001b[0m\n",
            "\u001b[38;20m[2026-01-02 17:43:22,504]::[InvokeAI]::INFO --> Started installation of https://huggingface.co/jerryytq/redcraftRedzimageUpdatedDEC03_redzimage15AIO/resolve/main/redcraftRedzimageUpdatedDEC03_redzimage15AIO.safetensors\u001b[0m\n",
            "\u001b[38;20m[2026-01-02 17:43:23,210]::[DownloadQueueService]::INFO --> File download started: https://huggingface.co/jerryytq/redcraftRedzimageUpdatedDEC03_redzimage15AIO/resolve/main/redcraftRedzimageUpdatedDEC03_redzimage15AIO.safetensors\u001b[0m\n",
            "\u001b[33;20m[2026-01-02 17:44:27,225]::[ModelInstallService]::WARNING --> Cancelling https://huggingface.co/jerryytq/redcraftRedzimageUpdatedDEC03_redzimage15AIO/resolve/main/redcraftRedzimageUpdatedDEC03_redzimage15AIO.safetensors\u001b[0m\n",
            "\u001b[38;20m[2026-01-02 17:44:30,382]::[ModelInstallService]::INFO --> Queueing model install: https://huggingface.co/jerryytq/redcraftRedzimageUpdatedDEC03_redzimage15AIO/resolve/main/redcraftRedzimageUpdatedDEC03_redzimage15AIO_fp8.safetensors (1 file)\u001b[0m\n",
            "\u001b[38;20m[2026-01-02 17:44:30,383]::[InvokeAI]::INFO --> Started installation of https://huggingface.co/jerryytq/redcraftRedzimageUpdatedDEC03_redzimage15AIO/resolve/main/redcraftRedzimageUpdatedDEC03_redzimage15AIO_fp8.safetensors\u001b[0m\n",
            "\u001b[38;20m[2026-01-02 17:44:30,730]::[DownloadQueueService]::INFO --> File download started: https://huggingface.co/jerryytq/redcraftRedzimageUpdatedDEC03_redzimage15AIO/resolve/main/redcraftRedzimageUpdatedDEC03_redzimage15AIO_fp8.safetensors\u001b[0m\n",
            "\u001b[33;20m[2026-01-02 17:44:31,693]::[DownloadQueueService]::WARNING --> Download cancelled: https://huggingface.co/jerryytq/redcraftRedzimageUpdatedDEC03_redzimage15AIO/resolve/main/redcraftRedzimageUpdatedDEC03_redzimage15AIO.safetensors\u001b[0m\n",
            "\u001b[38;20m[2026-01-02 17:45:13,017]::[DownloadQueueService]::INFO --> Download complete: https://huggingface.co/jerryytq/redcraftRedzimageUpdatedDEC03_redzimage15AIO/resolve/main/redcraftRedzimageUpdatedDEC03_redzimage15AIO_fp8.safetensors\u001b[0m\n",
            "\u001b[38;20m[2026-01-02 17:45:13,018]::[ModelInstallService]::INFO --> Model download complete: https://huggingface.co/jerryytq/redcraftRedzimageUpdatedDEC03_redzimage15AIO/resolve/main/redcraftRedzimageUpdatedDEC03_redzimage15AIO_fp8.safetensors\u001b[0m\n",
            "\u001b[38;20m[2026-01-02 17:45:13,019]::[ModelInstallService]::INFO --> Model install started: https://huggingface.co/jerryytq/redcraftRedzimageUpdatedDEC03_redzimage15AIO/resolve/main/redcraftRedzimageUpdatedDEC03_redzimage15AIO_fp8.safetensors\u001b[0m\n",
            "\u001b[31;20m[2026-01-02 17:45:13,440]::[ModelInstallService]::ERROR --> Model install error: https://huggingface.co/jerryytq/redcraftRedzimageUpdatedDEC03_redzimage15AIO/resolve/main/redcraftRedzimageUpdatedDEC03_redzimage15AIO_fp8.safetensors\n",
            "InvalidModelConfigException: Unable to determine model type\u001b[0m\n",
            "\u001b[38;20m[2026-01-02 17:49:27,455]::[InvokeAI]::INFO --> Emptying model cache.\u001b[0m\n",
            "/root/invokeai/.venv/lib/python3.12/site-packages/huggingface_hub/utils/_deprecation.py:131: FutureWarning: 'get_token_permission' (from 'huggingface_hub.hf_api') is deprecated and will be removed from version '1.0'. Permissions are more complex than when `get_token_permission` was first introduced. OAuth and fine-grain tokens allows for more detailed permissions. If you need to know the permissions associated with a token, please use `whoami` and check the `'auth'` key.\n",
            "  warnings.warn(warning_message, FutureWarning)\n",
            "\u001b[38;20m[2026-01-02 17:51:13,289]::[ModelInstallService]::INFO --> Queueing model install: mrfakename/Z-Image-Turbo (19 files)\u001b[0m\n",
            "\u001b[38;20m[2026-01-02 17:51:13,290]::[InvokeAI]::INFO --> Started installation of mrfakename/Z-Image-Turbo\u001b[0m\n",
            "\u001b[38;20m[2026-01-02 17:51:13,952]::[DownloadQueueService]::INFO --> File download started: https://huggingface.co/mrfakename/Z-Image-Turbo/resolve/main/tokenizer/merges.txt\u001b[0m\n",
            "\u001b[38;20m[2026-01-02 17:51:13,957]::[DownloadQueueService]::INFO --> File download started: https://huggingface.co/mrfakename/Z-Image-Turbo/resolve/main/tokenizer/vocab.json\u001b[0m\n",
            "\u001b[38;20m[2026-01-02 17:51:13,985]::[DownloadQueueService]::INFO --> File download started: https://huggingface.co/mrfakename/Z-Image-Turbo/resolve/main/model_index.json\u001b[0m\n",
            "\u001b[38;20m[2026-01-02 17:51:13,986]::[DownloadQueueService]::INFO --> Download complete: https://huggingface.co/mrfakename/Z-Image-Turbo/resolve/main/model_index.json\u001b[0m\n",
            "\u001b[38;20m[2026-01-02 17:51:14,011]::[DownloadQueueService]::INFO --> Download complete: https://huggingface.co/mrfakename/Z-Image-Turbo/resolve/main/tokenizer/merges.txt\u001b[0m\n",
            "\u001b[38;20m[2026-01-02 17:51:14,073]::[DownloadQueueService]::INFO --> File download started: https://huggingface.co/mrfakename/Z-Image-Turbo/resolve/main/text_encoder/model-00001-of-00003.safetensors\u001b[0m\n",
            "\u001b[38;20m[2026-01-02 17:51:14,202]::[DownloadQueueService]::INFO --> Download complete: https://huggingface.co/mrfakename/Z-Image-Turbo/resolve/main/tokenizer/vocab.json\u001b[0m\n",
            "\u001b[38;20m[2026-01-02 17:51:14,282]::[DownloadQueueService]::INFO --> File download started: https://huggingface.co/mrfakename/Z-Image-Turbo/resolve/main/transformer/diffusion_pytorch_model-00001-of-00003.safetensors\u001b[0m\n",
            "\u001b[38;20m[2026-01-02 17:51:14,577]::[DownloadQueueService]::INFO --> File download started: https://huggingface.co/mrfakename/Z-Image-Turbo/resolve/main/transformer/diffusion_pytorch_model-00003-of-00003.safetensors\u001b[0m\n",
            "\u001b[38;20m[2026-01-02 17:51:14,590]::[DownloadQueueService]::INFO --> File download started: https://huggingface.co/mrfakename/Z-Image-Turbo/resolve/main/text_encoder/model-00002-of-00003.safetensors\u001b[0m\n",
            "\u001b[38;20m[2026-01-02 17:51:14,721]::[DownloadQueueService]::INFO --> File download started: https://huggingface.co/mrfakename/Z-Image-Turbo/resolve/main/transformer/diffusion_pytorch_model-00002-of-00003.safetensors\u001b[0m\n",
            "\u001b[38;20m[2026-01-02 17:57:02,484]::[DownloadQueueService]::INFO --> Download complete: https://huggingface.co/mrfakename/Z-Image-Turbo/resolve/main/text_encoder/model-00002-of-00003.safetensors\u001b[0m\n",
            "\u001b[38;20m[2026-01-02 17:57:03,098]::[DownloadQueueService]::INFO --> File download started: https://huggingface.co/mrfakename/Z-Image-Turbo/resolve/main/text_encoder/generation_config.json\u001b[0m\n",
            "\u001b[38;20m[2026-01-02 17:57:03,101]::[DownloadQueueService]::INFO --> Download complete: https://huggingface.co/mrfakename/Z-Image-Turbo/resolve/main/text_encoder/generation_config.json\u001b[0m\n",
            "\u001b[38;20m[2026-01-02 17:57:03,573]::[DownloadQueueService]::INFO --> File download started: https://huggingface.co/mrfakename/Z-Image-Turbo/resolve/main/text_encoder/config.json\u001b[0m\n",
            "\u001b[38;20m[2026-01-02 17:57:03,576]::[DownloadQueueService]::INFO --> Download complete: https://huggingface.co/mrfakename/Z-Image-Turbo/resolve/main/text_encoder/config.json\u001b[0m\n",
            "\u001b[38;20m[2026-01-02 17:57:04,050]::[DownloadQueueService]::INFO --> File download started: https://huggingface.co/mrfakename/Z-Image-Turbo/resolve/main/transformer/diffusion_pytorch_model.safetensors.index.json\u001b[0m\n",
            "\u001b[38;20m[2026-01-02 17:57:04,053]::[DownloadQueueService]::INFO --> Download complete: https://huggingface.co/mrfakename/Z-Image-Turbo/resolve/main/transformer/diffusion_pytorch_model.safetensors.index.json\u001b[0m\n",
            "\u001b[38;20m[2026-01-02 17:57:04,540]::[DownloadQueueService]::INFO --> File download started: https://huggingface.co/mrfakename/Z-Image-Turbo/resolve/main/vae/config.json\u001b[0m\n",
            "\u001b[38;20m[2026-01-02 17:57:16,587]::[DownloadQueueService]::INFO --> Download complete: https://huggingface.co/mrfakename/Z-Image-Turbo/resolve/main/vae/config.json\u001b[0m\n",
            "\u001b[38;20m[2026-01-02 17:57:17,192]::[DownloadQueueService]::INFO --> File download started: https://huggingface.co/mrfakename/Z-Image-Turbo/resolve/main/vae/diffusion_pytorch_model.safetensors\u001b[0m\n",
            "\u001b[38;20m[2026-01-02 17:57:18,322]::[DownloadQueueService]::INFO --> Download complete: https://huggingface.co/mrfakename/Z-Image-Turbo/resolve/main/text_encoder/model-00001-of-00003.safetensors\u001b[0m\n",
            "\u001b[38;20m[2026-01-02 17:57:18,804]::[DownloadQueueService]::INFO --> File download started: https://huggingface.co/mrfakename/Z-Image-Turbo/resolve/main/tokenizer/tokenizer_config.json\u001b[0m\n",
            "\u001b[38;20m[2026-01-02 17:57:18,807]::[DownloadQueueService]::INFO --> Download complete: https://huggingface.co/mrfakename/Z-Image-Turbo/resolve/main/tokenizer/tokenizer_config.json\u001b[0m\n",
            "\u001b[38;20m[2026-01-02 17:57:19,269]::[DownloadQueueService]::INFO --> File download started: https://huggingface.co/mrfakename/Z-Image-Turbo/resolve/main/tokenizer/tokenizer.json\u001b[0m\n",
            "\u001b[38;20m[2026-01-02 17:57:23,273]::[DownloadQueueService]::INFO --> Download complete: https://huggingface.co/mrfakename/Z-Image-Turbo/resolve/main/tokenizer/tokenizer.json\u001b[0m\n",
            "\u001b[38;20m[2026-01-02 17:57:23,779]::[DownloadQueueService]::INFO --> File download started: https://huggingface.co/mrfakename/Z-Image-Turbo/resolve/main/text_encoder/model-00003-of-00003.safetensors\u001b[0m\n",
            "\u001b[38;20m[2026-01-02 17:57:29,467]::[DownloadQueueService]::INFO --> Download complete: https://huggingface.co/mrfakename/Z-Image-Turbo/resolve/main/vae/diffusion_pytorch_model.safetensors\u001b[0m\n",
            "\u001b[38;20m[2026-01-02 17:57:29,954]::[DownloadQueueService]::INFO --> File download started: https://huggingface.co/mrfakename/Z-Image-Turbo/resolve/main/transformer/config.json\u001b[0m\n",
            "\u001b[38;20m[2026-01-02 17:57:29,955]::[DownloadQueueService]::INFO --> Download complete: https://huggingface.co/mrfakename/Z-Image-Turbo/resolve/main/transformer/config.json\u001b[0m\n",
            "\u001b[38;20m[2026-01-02 17:57:30,127]::[DownloadQueueService]::INFO --> Download complete: https://huggingface.co/mrfakename/Z-Image-Turbo/resolve/main/text_encoder/model-00003-of-00003.safetensors\u001b[0m\n",
            "\u001b[38;20m[2026-01-02 17:57:30,439]::[DownloadQueueService]::INFO --> File download started: https://huggingface.co/mrfakename/Z-Image-Turbo/resolve/main/text_encoder/model.safetensors.index.json\u001b[0m\n",
            "\u001b[38;20m[2026-01-02 17:57:30,440]::[DownloadQueueService]::INFO --> Download complete: https://huggingface.co/mrfakename/Z-Image-Turbo/resolve/main/text_encoder/model.safetensors.index.json\u001b[0m\n",
            "\u001b[38;20m[2026-01-02 17:57:30,712]::[DownloadQueueService]::INFO --> File download started: https://huggingface.co/mrfakename/Z-Image-Turbo/resolve/main/scheduler/scheduler_config.json\u001b[0m\n",
            "\u001b[38;20m[2026-01-02 17:57:30,714]::[DownloadQueueService]::INFO --> Download complete: https://huggingface.co/mrfakename/Z-Image-Turbo/resolve/main/scheduler/scheduler_config.json\u001b[0m\n",
            "\u001b[38;20m[2026-01-02 17:57:40,840]::[DownloadQueueService]::INFO --> Download complete: https://huggingface.co/mrfakename/Z-Image-Turbo/resolve/main/transformer/diffusion_pytorch_model-00003-of-00003.safetensors\u001b[0m\n",
            "\u001b[38;20m[2026-01-02 18:01:19,479]::[DownloadQueueService]::INFO --> Download complete: https://huggingface.co/mrfakename/Z-Image-Turbo/resolve/main/transformer/diffusion_pytorch_model-00001-of-00003.safetensors\u001b[0m\n",
            "\u001b[38;20m[2026-01-02 18:01:33,086]::[DownloadQueueService]::INFO --> Download complete: https://huggingface.co/mrfakename/Z-Image-Turbo/resolve/main/transformer/diffusion_pytorch_model-00002-of-00003.safetensors\u001b[0m\n",
            "\u001b[38;20m[2026-01-02 18:01:33,087]::[ModelInstallService]::INFO --> Model download complete: mrfakename/Z-Image-Turbo\u001b[0m\n",
            "\u001b[38;20m[2026-01-02 18:01:33,088]::[ModelInstallService]::INFO --> Model install started: mrfakename/Z-Image-Turbo\u001b[0m\n",
            "\u001b[31;20m[2026-01-02 18:01:33,091]::[ModelInstallService]::ERROR --> Model install error: mrfakename/Z-Image-Turbo\n",
            "InvalidModelConfigException: Unable to determine model type\u001b[0m\n",
            "\u001b[38;20m[2026-01-02 18:28:10,085]::[ModelInstallService]::INFO --> Queueing model install: https://huggingface.co/IbarakiDouji/WAI-NSFW-illustrious-SDXL/resolve/main/waiNSFWIllustrious_v70.safetensors (1 file)\u001b[0m\n",
            "\u001b[38;20m[2026-01-02 18:28:10,085]::[InvokeAI]::INFO --> Started installation of https://huggingface.co/IbarakiDouji/WAI-NSFW-illustrious-SDXL/resolve/main/waiNSFWIllustrious_v70.safetensors\u001b[0m\n",
            "\u001b[38;20m[2026-01-02 18:28:10,814]::[DownloadQueueService]::INFO --> File download started: https://huggingface.co/IbarakiDouji/WAI-NSFW-illustrious-SDXL/resolve/main/waiNSFWIllustrious_v70.safetensors\u001b[0m\n",
            "\u001b[38;20m[2026-01-02 18:32:47,943]::[DownloadQueueService]::INFO --> Download complete: https://huggingface.co/IbarakiDouji/WAI-NSFW-illustrious-SDXL/resolve/main/waiNSFWIllustrious_v70.safetensors\u001b[0m\n",
            "\u001b[38;20m[2026-01-02 18:32:47,944]::[ModelInstallService]::INFO --> Model download complete: https://huggingface.co/IbarakiDouji/WAI-NSFW-illustrious-SDXL/resolve/main/waiNSFWIllustrious_v70.safetensors\u001b[0m\n",
            "\u001b[38;20m[2026-01-02 18:32:47,944]::[ModelInstallService]::INFO --> Model install started: https://huggingface.co/IbarakiDouji/WAI-NSFW-illustrious-SDXL/resolve/main/waiNSFWIllustrious_v70.safetensors\u001b[0m\n",
            "Hashing waiNSFWIllustrious_v70.safetensors: 100% 1/1 [00:31<00:00, 31.16s/file]\n",
            "\u001b[38;20m[2026-01-02 18:33:21,286]::[ModelInstallService]::INFO --> Model install complete: https://huggingface.co/IbarakiDouji/WAI-NSFW-illustrious-SDXL/resolve/main/waiNSFWIllustrious_v70.safetensors\u001b[0m\n",
            "\u001b[38;20m[2026-01-02 18:35:51,376]::[InvokeAI]::INFO --> Executing queue item 1, session 545feb90-39e3-4625-b2e9-4635a56986c9\u001b[0m\n",
            "Fetching 17 files:   0% 0/17 [00:00<?, ?it/s]\n",
            "model_index.json: 100% 609/609 [00:00<00:00, 3.90MB/s]\n",
            "Fetching 17 files:   6% 1/17 [00:00<00:04,  3.69it/s]\n",
            "merges.txt: 525kB [00:00, 68.9MB/s]\n",
            "\n",
            "vocab.json: 1.06MB [00:00, 91.2MB/s]\n",
            "\n",
            "special_tokens_map.json: 100% 472/472 [00:00<00:00, 5.00MB/s]\n",
            "\n",
            "tokenizer_config.json: 100% 737/737 [00:00<00:00, 6.45MB/s]\n",
            "\n",
            "config.json: 100% 565/565 [00:00<00:00, 6.11MB/s]\n",
            "\n",
            "scheduler_config.json: 100% 479/479 [00:00<00:00, 4.97MB/s]\n",
            "Fetching 17 files:  12% 2/17 [00:00<00:04,  3.59it/s]\n",
            "config.json: 100% 575/575 [00:00<00:00, 6.48MB/s]\n",
            "\n",
            "special_tokens_map.json: 100% 460/460 [00:00<00:00, 1.66MB/s]\n",
            "Fetching 17 files:  59% 10/17 [00:00<00:00, 19.10it/s]\n",
            "tokenizer_config.json: 100% 725/725 [00:00<00:00, 7.74MB/s]\n",
            "\n",
            "config.json: 1.68kB [00:00, 4.45MB/s]\n",
            "\n",
            "config.json: 100% 607/607 [00:00<00:00, 3.79MB/s]\n",
            "\n",
            "config.json: 100% 642/642 [00:00<00:00, 6.87MB/s]\n",
            "Fetching 17 files: 100% 17/17 [00:00<00:00, 20.32it/s]\n",
            "Loading pipeline components...: 100% 7/7 [00:01<00:00,  5.30it/s]\n",
            "\u001b[38;20m[2026-01-02 18:35:55,670]::[ModelManagerService]::INFO --> [MODEL CACHE] Loaded model '069c8090-c027-494f-919c-fa3723da36ad:text_encoder' (CLIPTextModel) onto cuda device in 1.22s. Total model size: 234.72MB, VRAM: 234.72MB (100.0%)\u001b[0m\n",
            "\u001b[38;20m[2026-01-02 18:35:55,675]::[ModelManagerService]::INFO --> [MODEL CACHE] Loaded model '069c8090-c027-494f-919c-fa3723da36ad:tokenizer' (CLIPTokenizer) onto cuda device in 0.00s. Total model size: 0.00MB, VRAM: 0.00MB (0.0%)\u001b[0m\n",
            "/root/invokeai/.venv/lib/python3.12/site-packages/compel/prompt_parser.py:598: DeprecationWarning: 'delimited_list' deprecated - use 'DelimitedList'\n",
            "  options = pp.Dict(pp.Optional(pp.delimited_list(option)))\n",
            "/root/invokeai/.venv/lib/python3.12/site-packages/compel/prompt_parser.py:666: DeprecationWarning: 'delimited_list' deprecated - use 'DelimitedList'\n",
            "  + pp.Group(pp.delimited_list(pp.Group(potential_operator_target | quoted_prompt), min=1)).set_name('bl-target').set_debug(False)\n",
            "/root/invokeai/.venv/lib/python3.12/site-packages/compel/prompt_parser.py:680: DeprecationWarning: 'delimited_list' deprecated - use 'DelimitedList'\n",
            "  + pp.Group(pp.delimited_list(pp.Group(potential_operator_target | quoted_prompt), min=1)).set_name('cj-target').set_debug(False)\n",
            "\u001b[38;20m[2026-01-02 18:36:01,052]::[ModelManagerService]::INFO --> [MODEL CACHE] Loaded model '069c8090-c027-494f-919c-fa3723da36ad:text_encoder_2' (CLIPTextModelWithProjection) onto cuda device in 4.21s. Total model size: 1324.96MB, VRAM: 1324.96MB (100.0%)\u001b[0m\n",
            "\u001b[38;20m[2026-01-02 18:36:01,057]::[ModelManagerService]::INFO --> [MODEL CACHE] Loaded model '069c8090-c027-494f-919c-fa3723da36ad:tokenizer_2' (CLIPTokenizer) onto cuda device in 0.00s. Total model size: 0.00MB, VRAM: 0.00MB (0.0%)\u001b[0m\n",
            "\u001b[38;20m[2026-01-02 18:36:01,247]::[ModelManagerService]::INFO --> [MODEL CACHE] Loaded model '069c8090-c027-494f-919c-fa3723da36ad:text_encoder' (CLIPTextModel) onto cuda device in 0.01s. Total model size: 234.72MB, VRAM: 234.72MB (100.0%)\u001b[0m\n",
            "\u001b[38;20m[2026-01-02 18:36:01,252]::[ModelManagerService]::INFO --> [MODEL CACHE] Loaded model '069c8090-c027-494f-919c-fa3723da36ad:tokenizer' (CLIPTokenizer) onto cuda device in 0.00s. Total model size: 0.00MB, VRAM: 0.00MB (0.0%)\u001b[0m\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (552 > 77). Running this sequence through the model will result in indexing errors\n",
            "\u001b[38;20m[2026-01-02 18:36:01,790]::[ModelManagerService]::INFO --> [MODEL CACHE] Loaded model '069c8090-c027-494f-919c-fa3723da36ad:text_encoder_2' (CLIPTextModelWithProjection) onto cuda device in 0.01s. Total model size: 1324.96MB, VRAM: 1324.96MB (100.0%)\u001b[0m\n",
            "\u001b[38;20m[2026-01-02 18:36:01,794]::[ModelManagerService]::INFO --> [MODEL CACHE] Loaded model '069c8090-c027-494f-919c-fa3723da36ad:tokenizer_2' (CLIPTokenizer) onto cuda device in 0.00s. Total model size: 0.00MB, VRAM: 0.00MB (0.0%)\u001b[0m\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (552 > 77). Running this sequence through the model will result in indexing errors\n",
            "Fetching 17 files: 100% 17/17 [00:00<00:00, 16091.89it/s]\n",
            "Loading pipeline components...: 100% 7/7 [00:00<00:00,  7.76it/s]\n",
            "\u001b[38;20m[2026-01-02 18:36:21,099]::[ModelManagerService]::INFO --> [MODEL CACHE] Loaded model '069c8090-c027-494f-919c-fa3723da36ad:unet' (UNet2DConditionModel) onto cuda device in 16.49s. Total model size: 4897.05MB, VRAM: 4897.05MB (100.0%)\u001b[0m\n",
            "Fetching 17 files: 100% 17/17 [00:00<00:00, 29846.45it/s]\n",
            "Loading pipeline components...: 100% 7/7 [00:01<00:00,  5.29it/s]\n",
            "\u001b[38;20m[2026-01-02 18:36:24,573]::[ModelManagerService]::INFO --> [MODEL CACHE] Loaded model '069c8090-c027-494f-919c-fa3723da36ad:scheduler' (EulerDiscreteScheduler) onto cuda device in 0.00s. Total model size: 0.00MB, VRAM: 0.00MB (0.0%)\u001b[0m\n",
            "100% 30/30 [00:27<00:00,  1.08it/s]\n",
            "Fetching 17 files: 100% 17/17 [00:00<00:00, 18680.42it/s]\n",
            "Loading pipeline components...: 100% 7/7 [00:00<00:00,  8.19it/s]\n",
            "estimate_vae_working_memory_sd15_sdxl: 9489612800\n",
            "\u001b[38;20m[2026-01-02 18:36:56,303]::[ModelManagerService]::INFO --> [MODEL CACHE] Loaded model '069c8090-c027-494f-919c-fa3723da36ad:vae' (AutoencoderKL) onto cuda device in 0.79s. Total model size: 159.56MB, VRAM: 159.56MB (100.0%)\u001b[0m\n",
            "\u001b[38;20m[2026-01-02 18:36:58,753]::[InvokeAI]::INFO --> Graph stats: 545feb90-39e3-4625-b2e9-4635a56986c9\n",
            "                          Node   Calls   Seconds  VRAM Used\n",
            "             sdxl_model_loader       1    0.012s     0.000G\n",
            "            sdxl_compel_prompt       2   11.051s     1.550G\n",
            "                       collect       2    0.002s     1.539G\n",
            "                        string       1    0.001s     1.539G\n",
            "                       integer       1    0.001s     1.539G\n",
            "                 core_metadata       1    0.002s     1.539G\n",
            "                         noise       1    0.012s     1.539G\n",
            "               denoise_latents       1   50.761s     5.200G\n",
            "                           l2i       1    5.493s     4.872G\n",
            "TOTAL GRAPH EXECUTION TIME:  67.335s\n",
            "TOTAL GRAPH WALL TIME:  67.349s\n",
            "RAM used by InvokeAI process: 4.61G (+3.580G)\n",
            "RAM used to load models: 6.46G\n",
            "VRAM in use: 0.302G\n",
            "RAM cache statistics:\n",
            "   Model cache hits: 11\n",
            "   Model cache misses: 4\n",
            "   Models cached: 6\n",
            "   Models cleared from cache: 1\n",
            "   Cache high water mark: 4.78/0.00G\n",
            "\u001b[0m\n",
            "\u001b[38;20m[2026-01-02 18:36:59,239]::[InvokeAI]::INFO --> Executing queue item 2, session 443dd2f1-c1b9-4efb-95e4-fa89a91d0184\u001b[0m\n",
            "Fetching 17 files: 100% 17/17 [00:00<00:00, 10458.08it/s]\n",
            "Loading pipeline components...: 100% 7/7 [00:01<00:00,  5.72it/s]\n",
            "\u001b[38;20m[2026-01-02 18:37:09,605]::[ModelManagerService]::INFO --> [MODEL CACHE] Loaded model '069c8090-c027-494f-919c-fa3723da36ad:unet' (UNet2DConditionModel) onto cuda device in 7.80s. Total model size: 4897.05MB, VRAM: 4897.05MB (100.0%)\u001b[0m\n",
            "Fetching 17 files: 100% 17/17 [00:00<00:00, 42619.95it/s]\n",
            "Loading pipeline components...: 100% 7/7 [00:02<00:00,  2.67it/s]\n",
            "\u001b[38;20m[2026-01-02 18:37:15,653]::[ModelManagerService]::INFO --> [MODEL CACHE] Loaded model '069c8090-c027-494f-919c-fa3723da36ad:scheduler' (EulerDiscreteScheduler) onto cuda device in 0.00s. Total model size: 0.00MB, VRAM: 0.00MB (0.0%)\u001b[0m\n",
            "100% 30/30 [00:27<00:00,  1.08it/s]\n",
            "Fetching 17 files: 100% 17/17 [00:00<00:00, 41869.15it/s]\n",
            "Loading pipeline components...: 100% 7/7 [00:00<00:00,  9.03it/s]\n",
            "estimate_vae_working_memory_sd15_sdxl: 9489612800\n",
            "\u001b[38;20m[2026-01-02 18:37:46,294]::[ModelManagerService]::INFO --> [MODEL CACHE] Loaded model '069c8090-c027-494f-919c-fa3723da36ad:vae' (AutoencoderKL) onto cuda device in 0.65s. Total model size: 159.56MB, VRAM: 159.56MB (100.0%)\u001b[0m\n",
            "\u001b[38;20m[2026-01-02 18:37:48,519]::[InvokeAI]::INFO --> Graph stats: 443dd2f1-c1b9-4efb-95e4-fa89a91d0184\n",
            "                          Node   Calls   Seconds  VRAM Used\n",
            "             sdxl_model_loader       1    0.001s     0.302G\n",
            "            sdxl_compel_prompt       2    0.008s     0.302G\n",
            "                       collect       2    0.001s     0.302G\n",
            "                        string       1    0.000s     0.302G\n",
            "                       integer       1    0.001s     0.302G\n",
            "                 core_metadata       1    0.003s     0.302G\n",
            "                         noise       1    0.009s     0.302G\n",
            "               denoise_latents       1   44.150s     5.200G\n",
            "                           l2i       1    5.066s     4.872G\n",
            "TOTAL GRAPH EXECUTION TIME:  49.239s\n",
            "TOTAL GRAPH WALL TIME:  49.256s\n",
            "RAM used by InvokeAI process: 3.36G (-1.247G)\n",
            "RAM used to load models: 4.94G\n",
            "VRAM in use: 0.302G\n",
            "RAM cache statistics:\n",
            "   Model cache hits: 3\n",
            "   Model cache misses: 3\n",
            "   Models cached: 6\n",
            "   Models cleared from cache: 1\n",
            "   Cache high water mark: 4.78/0.00G\n",
            "\u001b[0m\n",
            "/root/invokeai/.venv/lib/python3.12/site-packages/huggingface_hub/utils/_deprecation.py:131: FutureWarning: 'get_token_permission' (from 'huggingface_hub.hf_api') is deprecated and will be removed from version '1.0'. Permissions are more complex than when `get_token_permission` was first introduced. OAuth and fine-grain tokens allows for more detailed permissions. If you need to know the permissions associated with a token, please use `whoami` and check the `'auth'` key.\n",
            "  warnings.warn(warning_message, FutureWarning)\n",
            "\u001b[38;20m[2026-01-02 18:40:14,202]::[ModelInstallService]::INFO --> Queueing model install: https://github.com/JingyunLiang/SwinIR/releases/download/v0.0/003_realSR_BSRGAN_DFOWMFC_s64w8_SwinIR-L_x4_GAN-with-dict-keys-params-and-params_ema.pth (1 file)\u001b[0m\n",
            "\u001b[38;20m[2026-01-02 18:40:14,202]::[InvokeAI]::INFO --> Started installation of https://github.com/JingyunLiang/SwinIR/releases/download/v0.0/003_realSR_BSRGAN_DFOWMFC_s64w8_SwinIR-L_x4_GAN-with-dict-keys-params-and-params_ema.pth\u001b[0m\n",
            "\u001b[38;20m[2026-01-02 18:40:14,656]::[DownloadQueueService]::INFO --> File download started: https://github.com/JingyunLiang/SwinIR/releases/download/v0.0/003_realSR_BSRGAN_DFOWMFC_s64w8_SwinIR-L_x4_GAN-with-dict-keys-params-and-params_ema.pth\u001b[0m\n",
            "\u001b[38;20m[2026-01-02 18:40:19,969]::[DownloadQueueService]::INFO --> Download complete: https://github.com/JingyunLiang/SwinIR/releases/download/v0.0/003_realSR_BSRGAN_DFOWMFC_s64w8_SwinIR-L_x4_GAN-with-dict-keys-params-and-params_ema.pth\u001b[0m\n",
            "\u001b[38;20m[2026-01-02 18:40:19,969]::[ModelInstallService]::INFO --> Model download complete: https://github.com/JingyunLiang/SwinIR/releases/download/v0.0/003_realSR_BSRGAN_DFOWMFC_s64w8_SwinIR-L_x4_GAN-with-dict-keys-params-and-params_ema.pth\u001b[0m\n",
            "\u001b[38;20m[2026-01-02 18:40:19,970]::[ModelInstallService]::INFO --> Model install started: https://github.com/JingyunLiang/SwinIR/releases/download/v0.0/003_realSR_BSRGAN_DFOWMFC_s64w8_SwinIR-L_x4_GAN-with-dict-keys-params-and-params_ema.pth\u001b[0m\n",
            "/root/invokeai/.venv/lib/python3.12/site-packages/torch/functional.py:554: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /pytorch/aten/src/ATen/native/TensorShape.cpp:4314.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            "Hashing 003_realSR_BSRGAN_DFOWMFC_s64w8_SwinIR-L_x4_GAN-with-dict-keys-params-and-params_ema.pth: 100% 1/1 [00:00<00:00,  8.16file/s]\n",
            "\u001b[38;20m[2026-01-02 18:40:21,882]::[ModelInstallService]::INFO --> Model install complete: https://github.com/JingyunLiang/SwinIR/releases/download/v0.0/003_realSR_BSRGAN_DFOWMFC_s64w8_SwinIR-L_x4_GAN-with-dict-keys-params-and-params_ema.pth\u001b[0m\n",
            "\u001b[38;20m[2026-01-02 18:42:11,625]::[InvokeAI]::INFO --> Executing queue item 3, session 49a49121-8fdd-4c69-a3a7-bd88b75bf40c\u001b[0m\n",
            "estimate_vae_working_memory_sd15_sdxl: 4875878400\n",
            "\u001b[38;20m[2026-01-02 18:42:11,937]::[ModelManagerService]::INFO --> [MODEL CACHE] Loaded model '069c8090-c027-494f-919c-fa3723da36ad:vae' (AutoencoderKL) onto cuda device in 0.01s. Total model size: 159.56MB, VRAM: 159.56MB (100.0%)\u001b[0m\n",
            "Fetching 17 files: 100% 17/17 [00:00<00:00, 44260.19it/s]\n",
            "Loading pipeline components...: 100% 7/7 [00:00<00:00,  8.31it/s]\n",
            "\u001b[38;20m[2026-01-02 18:42:32,990]::[ModelManagerService]::INFO --> [MODEL CACHE] Loaded model '069c8090-c027-494f-919c-fa3723da36ad:unet' (UNet2DConditionModel) onto cuda device in 17.70s. Total model size: 4897.05MB, VRAM: 4897.05MB (100.0%)\u001b[0m\n",
            "Fetching 17 files: 100% 17/17 [00:00<00:00, 145814.25it/s]\n",
            "Loading pipeline components...: 100% 7/7 [00:01<00:00,  4.75it/s]\n",
            "\u001b[38;20m[2026-01-02 18:42:36,719]::[ModelManagerService]::INFO --> [MODEL CACHE] Loaded model '069c8090-c027-494f-919c-fa3723da36ad:scheduler' (EulerDiscreteScheduler) onto cuda device in 0.00s. Total model size: 0.00MB, VRAM: 0.00MB (0.0%)\u001b[0m\n",
            "100% 21/21 [00:19<00:00,  1.10it/s]\n",
            "Fetching 17 files: 100% 17/17 [00:00<00:00, 19476.42it/s]\n",
            "Loading pipeline components...: 100% 7/7 [00:00<00:00,  8.65it/s]\n",
            "estimate_vae_working_memory_sd15_sdxl: 9489612800\n",
            "\u001b[38;20m[2026-01-02 18:42:58,296]::[ModelManagerService]::INFO --> [MODEL CACHE] Loaded model '069c8090-c027-494f-919c-fa3723da36ad:vae' (AutoencoderKL) onto cuda device in 0.10s. Total model size: 159.56MB, VRAM: 159.56MB (100.0%)\u001b[0m\n",
            "\u001b[38;20m[2026-01-02 18:43:00,787]::[InvokeAI]::INFO --> Graph stats: 49a49121-8fdd-4c69-a3a7-bd88b75bf40c\n",
            "                          Node   Calls   Seconds  VRAM Used\n",
            "             sdxl_model_loader       1    0.001s     0.302G\n",
            "          create_gradient_mask       1    0.131s     0.302G\n",
            "         expand_mask_with_fade       1    0.133s     0.302G\n",
            "                           i2l       1    1.217s     2.833G\n",
            "            sdxl_compel_prompt       2    0.003s     0.321G\n",
            "                       collect       2    0.001s     0.321G\n",
            "                        string       1    0.000s     0.321G\n",
            "                       integer       1    0.000s     0.321G\n",
            "                 core_metadata       1    0.001s     0.321G\n",
            "                         noise       1    0.004s     0.321G\n",
            "               denoise_latents       1   42.677s     5.201G\n",
            "                           l2i       1    4.712s     4.872G\n",
            "           apply_mask_to_image       1    0.218s     0.302G\n",
            "TOTAL GRAPH EXECUTION TIME:  49.097s\n",
            "TOTAL GRAPH WALL TIME:  49.121s\n",
            "RAM used by InvokeAI process: 4.27G (+0.355G)\n",
            "RAM used to load models: 4.94G\n",
            "VRAM in use: 0.302G\n",
            "RAM cache statistics:\n",
            "   Model cache hits: 4\n",
            "   Model cache misses: 3\n",
            "   Models cached: 6\n",
            "   Models cleared from cache: 1\n",
            "   Cache high water mark: 4.78/0.00G\n",
            "\u001b[0m\n",
            "/root/invokeai/.venv/lib/python3.12/site-packages/huggingface_hub/utils/_deprecation.py:131: FutureWarning: 'get_token_permission' (from 'huggingface_hub.hf_api') is deprecated and will be removed from version '1.0'. Permissions are more complex than when `get_token_permission` was first introduced. OAuth and fine-grain tokens allows for more detailed permissions. If you need to know the permissions associated with a token, please use `whoami` and check the `'auth'` key.\n",
            "  warnings.warn(warning_message, FutureWarning)\n",
            "\u001b[38;20m[2026-01-02 18:44:45,404]::[ModelInstallService]::INFO --> Queueing model install: InstantX/FLUX.1-dev-Controlnet-Union (2 files)\u001b[0m\n",
            "\u001b[38;20m[2026-01-02 18:44:45,404]::[InvokeAI]::INFO --> Started installation of InstantX/FLUX.1-dev-Controlnet-Union\u001b[0m\n",
            "\u001b[38;20m[2026-01-02 18:44:45,825]::[DownloadQueueService]::INFO --> File download started: https://huggingface.co/InstantX/FLUX.1-dev-Controlnet-Union/resolve/main/config.json\u001b[0m\n",
            "\u001b[38;20m[2026-01-02 18:44:45,826]::[DownloadQueueService]::INFO --> Download complete: https://huggingface.co/InstantX/FLUX.1-dev-Controlnet-Union/resolve/main/config.json\u001b[0m\n",
            "\u001b[38;20m[2026-01-02 18:44:45,910]::[DownloadQueueService]::INFO --> File download started: https://huggingface.co/InstantX/FLUX.1-dev-Controlnet-Union/resolve/main/diffusion_pytorch_model.safetensors\u001b[0m\n",
            "\u001b[38;20m[2026-01-02 18:46:53,360]::[DownloadQueueService]::INFO --> Download complete: https://huggingface.co/InstantX/FLUX.1-dev-Controlnet-Union/resolve/main/diffusion_pytorch_model.safetensors\u001b[0m\n",
            "\u001b[38;20m[2026-01-02 18:46:53,360]::[ModelInstallService]::INFO --> Model download complete: InstantX/FLUX.1-dev-Controlnet-Union\u001b[0m\n",
            "\u001b[38;20m[2026-01-02 18:46:53,362]::[ModelInstallService]::INFO --> Model install started: InstantX/FLUX.1-dev-Controlnet-Union\u001b[0m\n",
            "Hashing diffusion_pytorch_model.safetensors: 100% 1/1 [00:29<00:00, 29.65s/file]\n",
            "\u001b[38;20m[2026-01-02 18:47:23,032]::[ModelInstallService]::INFO --> Model install complete: InstantX/FLUX.1-dev-Controlnet-Union\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ğŸ‰ Â¡Todo listo!\n",
        "Ya puedes usar la interfaz de Invoke AI para generar imÃ¡genes con total libertad.\n",
        "\n",
        "ğŸ–¼ï¸ Si quieres mÃ¡s tutoriales o contenido exclusivo, visita [ArteIA en YouTube](https://www.youtube.com/@arteia)<br>\n",
        "\n",
        "<br>\n",
        "Este notebook estÃ¡ distribuido bajo licencia Creative Commons <br> Attribution-NonCommercial 4.0 International (CC BY-NC 4.0)\n",
        "<br>\n",
        "Â©2025 ArteIA\n"
      ],
      "metadata": {
        "id": "Jw1YA-ykviB1"
      }
    }
  ]
}